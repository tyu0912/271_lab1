---
title: "W271 Lab 1: Challenger O-ring Analysis"
author: "Christian Millsop & Tennison Yu"
date: "January 22, 2019"
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, echo=FALSE, warning=FALSE, message=FALSE)
```

**Abstract**



**Introduction**

On January 28, 1986, the Challenger spacerocket suffered catastrophic failure due to O-ring failures inside the solid rocket motors of the booster. As a case study, we emulate the analysis done by Dalal et al. (1989) by following questions 4 and 5 found in the exercise section of Chapter 2 of *Analysis of Categorical Data* (2015) by Christopher R. Bilder and Thomas M. Loughin. 

This report will feature an EDA section, followed by modeling and discussion. The latter of which will draw heavily from the exercise questions stated above. We will then conclude by summarizing our findings and presenting potential future work and considerations. 

Note that the questions themselves can be found in the appendix and we will refer accordingly when we answer a question.

**EDA**

The below r snippet is to import the data and the packages we will be using. The data (challenger.csv) can be found here: http://www.chrisbilder.com/categorical/programs_and_data.html

```{r}
library(package = car)
challenger = read.table(file="challenger.csv", sep=",", header = TRUE)
str(challenger)
```
Looking at the summary above, we are working with 23 rows and 5 columns of data. The columns include information such as

- Flight: Flight Number

- Temp: Temperature (F) at launch

- Pressure: Combustion pressure (psi)

- O.ring: Number of primary field O-ring failures

- Number: Total number of primary field O-rings (six total, three each for the two booster rockets)


The response variable is O.ring, and the explanatory variables are Temp and Pressure. By dividing O.ring by Number, we can also get the percent that failed during each flight. 

---
/*Maybe a good EDA would be plotting the relationship of temperature and pressure*/
---

**Modeling & Discussion**

In answering question 4a, one way to potentially model our data is to use logistic regression with the consideration that the O-rings are thought of as a binomial variable, where each ring is independent of one another and is governed by a probability of sucess and failure. 

However, this is potentially problematic because each of the O-rings are located in a different part of the solid rocket motors (3 sets in each rocket). Operational anomalies that occur in a rocket likely affect all O-rings on the rocket. In terms of the rockets, rocket motors can potentially be re-used. Are O-rings replaced each time? The paper also details the existence of secondary O-rings and although it is the primary O-ring that undergoes significantly more stress the behavior of the primary O-ring seems to strongly dictate the behavior of the second O-ring. Joint rotation in the primary can cause the secondary to lose contact with the tang and enable gas release. This essentially means that each trial is not likely to be independent of one another and there are likely other variables involved as well.

To rectify this, the authors instead considered the random variable to be binary/bernoulli. ie. instead of looking at O-ring failures, they decided to just look at whether the rocket launched successfully or not (0 if no accident/1 if accident). This essentially eliminated the need to for the combinations term in the data and simplified things for them. For the purposes of this exercise though, we stick to the binomial case and will attempt to model to the equation:

$$logit(\pi) = \beta_0 + \beta_1Temp + \beta_2Pressure$$

where $\pi = p(t,s)/(1-p(t,s))$ and $p(t,s)$ comes from the binomial distribution $P(X=k) = nCk*p(t,s)^k * (1-p(t,s))^{n-k}$. As part of question 4b we proceed to model the data in linear form.

```{r}
prob = challenger$O.ring/challenger$Number

mod.1 <- glm(
formula = prob ~ Temp + Pressure, 
family = binomial(link = logit),
data = challenger
)

summary(mod.1)
```

Looking at the data above, we get the model:

$$logit(\pi) = 2.520 + -0.098Temp + 0.008Pressure$$
This first attempt at modeling seems to indicate that every one unit increase in temperature will decrease the chance of failure by 0.098 units whereas a every unit increase in pressure will cause a 0.008 unit increase in chance of failure. This seems to make sense as low temperature can make O-rings shrink and not seal properly and high pressure would be additional stress. Looking at the p-values though, it seems that neither variable is extremely significant. With a lower p-value, temperature seems to be more important than pressure. As part of question 4c, we look perform the likelihood ratio test (LRT). 

```{r}
cat("\nBelow results are with Anova (cat package)\n")
Anova(mod.1, test = "LR")

cat("\nBelow results are with anova package\n")
anova(mod.1, test = "Chisq")

mod.1.noPressure <- glm(
formula = prob ~ Temp, 
family = binomial(link = logit),
data = challenger 
)

mod.1.noTemperature <- glm(
formula = prob ~ Pressure, 
family = binomial(link = logit),
data = challenger 
)

cat("\nBelow results are without pressure\n")
anova(mod.1.noPressure, mod.1, test = "Chisq")

cat("\nBelow results are without temperature\n")
anova(mod.1.noTemperature, mod.1, test = "Chisq")
```
d
**Conclusion**



**Appendix**

(4a) The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

(4b) Estimate the logistic regression model using the explanatory variables in a linear form.

(4c) Perform LRTs to judge the importance of the explanatory variables in the model.

(4d) The temperature was $31\textdegree$ at launch for the Challenger in 1986.  Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval.  Discuss what assumptions need to be made in order to apply the inference procedures.

```{r}
predicted_odds = predict(fit.b, newdata=data.frame(Temp=31), type="link", se.fit = TRUE)
predicted_prob = exp(predicted_odds$fit)/(1+exp(predicted_odds$fit))
ci_odds = c(predicted_odds$fit - qnorm(1-.05/2)*predicted_odds$se.fit, predicted_odds$fit + qnorm(1-.05/2)*predicted_odds$se.fit)
ci = exp(ci_odds)/(1+exp(ci_odds))
"Predicted probability of at least one O-ring failure with 95% confidence interval:"
paste(round(ci[1],5), "<", round(predicted_prob,5), "<", round(ci[2],5))
```

Based on all the LRTs done above, it seems that pressure does not explain the behavior as much as temperature does. It seems that the authors analysis coincided with this conclusion. In all instances, the p-value of the temperature is much lower that of pressure. However, the p-value is not so low that it would not pass the traditional alpha values of something being significant. This suggests that pressure, though not as much as temperature, is likely still to have an effect. This is in contrast to if the p-value for one of the variables like temperature would be much lower (ie. <0.001).

High pressure causing blowholes. 

To remove the variable, it does open the potential for the model to not fully explain the variance and overall predictive power as well. 


5. Continuing Exercise 4, consider the simplified model $logit(\pi) = \beta_0 + \beta_1Temp$ where $\pi$ is the probability of an O-ring failure. Complete the following:

(a) Estimate the model.

```{r}
mod.1.noPressure <- glm(
formula = prob ~ Temp, 
family = binomial(link = logit),
data = challenger 
)

summary(mod.1.noPressure)
```

(b) Construct two plots: (1) $\pi$ vs. Temp and (2) Expected number of failures vs. Temp. Use a temperature range of 31 to 81 degrees on the x-axis even though the minimum temperature in the data set was 53 degrees.

```{r}

pred <- data.frame(Temp=seq(31,81))
pred.results <- predict(mod.1.noPressure, pred, type = "link", se = TRUE)

pi = exp(pred.results$fit)

plot(pred$Temp, pi, ylab = "pi", xlab = "Temp")

n = 6
pi.expected.prob = pi/(1+pi)
pi.expected.oring = n*pi.expected.prob

plot(pred$Temp, pi.expected.oring, ylab = "Expected Number of Failures", xlab = "Temp")

```

(c) Include the 95% Wald confidence interval bands for on the plot. Why are the bands much wider for lower temperatures than for higher temperatures?

```{r}
alpha = 0.05

pi.ci.lower <- exp(pred.results$fit - qnorm(p =1-alpha /2)*pred.results$se)
pi.ci.upper <- exp(pred.results$fit + qnorm(p =1-alpha /2)*pred.results$se)

pi.expected.ci.lower.prob <- (pi.ci.lower/(1+pi.ci.lower))
pi.expected.ci.upper.prob <- (pi.ci.upper/(1+pi.ci.upper))

pi.expected.ci.lower.oring <- n*pi.expected.ci.lower.prob
pi.expected.ci.upper.oring <- n*pi.expected.ci.upper.prob

results.collection <- data.frame(
Temp=pred$Temp,
pi,
pi.ci.lower,
pi.ci.upper,
pi.expected.oring,
pi.expected.ci.lower.oring, 
pi.expected.ci.upper.oring,
pi.expected.prob, 
pi.expected.ci.lower.prob,
pi.expected.ci.upper.prob
)

matplot(results.collection$Temp, results.collection[,2:4], pch=19 ,col = 1:3, ylab = "pi", xlab = "Temp")
matplot(results.collection$Temp, results.collection[,8:10], pch=19 ,col = 1:3, ylab = "prob", xlab = "Temp")

```

Looking above, the gap is wider at lower temperatures because we did not have data at those temperatures to model. This is especially evident since it can be see that around 50 degrees, the gap starts to close and it is exactly around this region where we start having data. 

(d) The temperature was 31 degrees at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in
order to apply the inference procedures.

```{r}
head(results.collection,1)

```

At 31 degrees, it seems there's about 81.8% chance of failure. However, this chance should be taken cautiously. As discussed previously, there is no data below the 50 degree region therefore as validated by the large confidence interval gap, it's hard to say how accurate that zone of prediction is. We would have to assume that below 50 degrees, the behavior is linear per the model and that the effect of pressure does not change or somehow become more dominant in that zone. 

(e) Rather than using Wald or profile LR intervals for the probability of failure, Dalal et al. (1989) use a parametric bootstrap to compute intervals. Their process was to (1) simulate a large number of data sets (n = 23 for each) from the estimated model of $logit(\hat{\pi}) = \hat{\beta_0} + \hat{\beta_1}Temp$; (2) estimate new models for each data set,
say $logit(\hat{\pi^{*}}) = \hat{\beta_0^{*}} + \hat{\beta_1^{*}}Temp$; and (3) compute $\hat{\pi^{*}}$ at a specific temperature of interest. The authors used the 0.05 and 0.95 observed quantiles from the $\hat{\pi^{*}}$ simulated distribution as their 90% confidence interval limits. Using the parametric bootstrap, compute 90% confidence intervals separately at temperatures of 31 and 72 degrees.

```{r}
# Sampling from temperature side and then applying to model -> No real randomness here. How can I guarantee the numbers I pick are random?? It wouldn't give the right pi inside the logit either. 
# Sampling from P(X=0 successes (ie. >= 1 failure)) side is running into potentially infinite values if I do random binomial sample with the propabilities.

get_bootstrap_ci = function(df_number, temp){

vector <- vector("numeric")
set.seed(1)

for (i in 1:df_number) {

df.tmp <- challenger[sample(nrow(challenger), 23, replace = TRUE), ]

mod.1.tmp <- glm(
formula = prob ~ Temp, 
family = binomial(link = logit),
data = df.tmp 
)

pred.value <- data.frame(Temp=temp)
pred.result <- predict(mod.1.tmp, pred.value, type = "link", se = TRUE)
vector[i] <- exp(pred.result$fit)

}

results_sorted = sort(vector)

cat("For temp",temp,"lower ci of pi:",results_sorted[df_number*0.05], ",upper ci of pi:",results_sorted[df_number*0.95],"\n")

}

get_bootstrap_ci(100, 31)
get_bootstrap_ci(100, 72)

```

(f) Determine if a quadratic term is needed in the model for the temperature.

```{r}
mod.temp.squared <- glm(
formula = prob ~ Temp + I(Temp^2), 
family = binomial(link = logit),
data = challenger 
)

summary(mod.temp.squared)

anova(mod.1.noPressure,mod.temp.squared, test = "Chisq")

```

Given the high p-value of the squared term in both the model summary and anova test, it doesn't seem like the squared term is necessary. 


3a. Interpret the main result of your final model in terms of both odds and probability of failure.

The final model is $logit(\pi) = \beta_0 + \beta_1Temp$. In terms of odds, we can see that the odds ratio can be calculated simply as $\frac{exp(\beta_0 + \beta_1(Temp+c))}{exp(\beta_0 + \beta_1(Temp))}$ which simplifies to $exp(c\beta_1)$. Thusly, because the coefficient of temp is -0.1156, the estimated odds of an O-ring failing decreases by 0.890 times for every c-unit increases in temp. In terms of the probability of failure as seen below, it is very clear that the probability of there being a failure is high when the temperature is low (81.2% at 31 degrees) and this changes as the temperature increases (1.36% at 81 degrees).

```{r}
head(results.collection,10)
```

3b. 

```{r}
mod.lin <- lm(

formula = prob ~ Temp, 
data = challenger 

)

summary(mod.lin)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(mod.lin, las = 1)
```

**Hmm, maybe having quadratic is a good idea??**

Looking at the above diagnostic plots of the linear model $prob = \beta_0 + \beta_1Temp$, we can see that it is not ideal. The residual vs fitted and scale-location plot indicate some sort of non-linear relationship in the data and that the variance is not constant across samples (heteroscadastic). Furthermore, there appears to be outliers. Data points, 14 and 21 are marked above as having considerable leverage. In the data, these were cases where 2 O-rings failed instead of either 1 or 0. Because the vast majority of data points are those where O-rings only failed once or not at all, these two data points are skewing the model. In addition like logistic regression, this model would need independence from all discriptive variables and that is not the case as seen with pressure having some kind of affect. 

Overall, I would prefer to use the binary logistic model since it is a more conservative model in its approach. A logistic model is advantageous since it does not require a linear relationship between the dependent and independent variables, the residuals do not need to be normally distributed and lastly, homoscedasticity is not required. Also, a logistic model outputs probabilities as its main result. This is much more useful given the circumstance since one O-ring failure is all that's needed for catastrophic disaster. In other words, its easier to say "what is the probability of failure with these given conditions" via the logistic model versus "What conditions will lead to a prediction of 1 or more".


*When the sample size is small, there is a substantial probability that AIC will select models that have too many parameters, i.e. that AIC will overfit.[7][8][9] To address such potential overfitting, AICc was developed: AICc is AIC with a correction for small sample sizes.
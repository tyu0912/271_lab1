---
title: "W271 Lab 1: Challenger O-ring Analysis"
author: "Christian Millsop & Tennison Yu"
date: "January 22, 2019"
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, echo=FALSE, warning=FALSE, message=FALSE)
```

**Abstract**

In this report, a statisical model of the probability of O-ring failure on the space shuttle Challenger is presented.  An 81.8% probability of O-ring failure was determined based upon a binary logistic regression model.  Multiple alternative models were also explored.  This analysis was inspired by the work of Dalal et al (1989).

**Introduction**

On January 28, 1986, the Challenger spacerocket suffered catastrophic failure due to O-ring failures inside the solid rocket motors of the booster. As a case study, we emulate the analysis done by Dalal et al. (1989) by following questions 4 and 5 found in the exercise section of Chapter 2 of *Analysis of Categorical Data* (2015) by Christopher R. Bilder and Thomas M. Loughin. 

The goal of this analysis of this analysis is to develop a model to predict the probability that the Challenger would fail under the conditions experienced, temperature of 31F.

This report will feature an EDA section, followed by modeling and discussion. The latter of which will draw heavily from the exercise questions stated above. We will then conclude by summarizing our findings and presenting potential future work and considerations. 

Note that the questions themselves can be found in the appendix and we will refer accordingly to them in square brackets ([]) when we incorporate and address a question.

**EDA**

The below r snippet is to import the data and the packages we will be using. The data (challenger.csv) can be found here: http://www.chrisbilder.com/categorical/programs_and_data.html

```{r}
library(package = car)
library(package = skimr)
library(package = stargazer)
challenger = read.table(file="challenger.csv", sep=",", header = TRUE)
str(challenger)
```
Looking at the description above, we are working with 23 rows and 5 columns of data. The columns include information such as

- Flight: Flight Number

- Temp: Temperature (F) at launch

- Pressure: Combustion pressure (psi)

- O.ring: Number of primary field O-rings with damage

- Number: Total number of primary field O-rings (six total, three each for the two booster rockets)

The response variable is O.ring, and the explanatory variables are Temp and Pressure. By dividing O.ring by Number, we can also get the percent that failed during each flight.

A tabular and graphical examination of the data illustrates the general distributions and relationships of the response and explanatory variables.
- Temp and O-ring have a strong, negative correlation
- Pressure and O-ring have a weak, positive correlation
- Temp observations ar clustered around 70.
- O-ring damage, in general, is an uncommon event

A summary of the explanatory and response variables below shows the general distribution and ranges.
```{r}
skim(challenger[,c("Pressure", "Temp", "O.ring")])
scatterplotMatrix(~ Temp + Pressure + O.ring, data=challenger, smooth = FALSE)
```

Based upon background research, the primary failure mode of the O-rings is by thermal erosion.  This occurs when the O-rings are exposed to hot gas that is a product of the rocket reaction.

We also understand that the mechanical properties of the O-rings are highly dependent upon the ambient temperature.  The durometer increases and the compressibility decreases as temperature decreases.  Under low temperature conditions the O-rings might not seal the cavity within the rocket as designed.  This allows hot gas to escape and then damage the O-rings.

Pressure might play a role in O-ring damage, but it is unclear how significant that is.  Under pressure conditions, the sealant that is designed to protect the O-rings can be penetrated by pressurized gas, thus exposing the O-ring to thermal erosion.

**Modeling & Discussion**

Using the exploratory data analysis and background research as a starting point we seek to develop a model including the terms $Temp$ and $Pressure$ to predict the probability of O-ring failure.  One way to model our data is to use logistic regression with the consideration that the O-rings are thought of as a binomial variable, where each ring is independent of one another and is governed by a probability of sucess and failure. 

However, this is potentially problematic because each of the O-rings are located in a different part of the solid rocket motors (3 sets in each rocket). Operational anomalies that occur in a rocket likely affect all O-rings on the rocket. In terms of the rockets, rocket motors can potentially be re-used. Are O-rings replaced each time? The paper also details the existence of secondary O-rings and although it is the primary O-ring that undergoes significantly more stress the behavior of the primary O-ring seems to strongly dictate the behavior of the second O-ring. Joint rotation in the primary can cause the secondary to lose contact with the tang and enable gas release. This essentially means that each trial is not likely to be independent of one another and there are likely other variables involved as well. [4a]

To rectify this, the authors instead considered the random variable to be binary/Bernoulli. ie. instead of looking at O-ring failures, they decided to just look at whether the rocket launched successfully or not (0 if no accident/1 if accident). This essentially eliminated the need to for the combinations term in the data and simplified things for them. For the purposes of this exercise though, we stick to the binomial case.

The models that we propose are:

+ A complete model accounting for influence of Temp and Pressure. [4b]

$$(1): logit(\pi) = \beta_0 + \beta_1Temp + \beta_2Pressure$$
+ A reduced model focusing on Temp since our background research suggests that this influences performance of the O-rings the most. [5a]
$$(2): logit(\pi) = \beta_0 + \beta_1Temp$$
+ A quadratic model since the distribution of Temp vs O-ring data suggests that the data could have a non-linear relationship. [5f]
$$(3): logit(\pi) = \beta_0 + \beta_1Temp + \beta_2Temp^2$$

where $\pi = p(t,s)/(1-p(t,s))$ or $\pi = p(t)/(1-p(t))$, and $p(t,s)$ comes from the binomial distribution $P(X=k) = nCk*p(t,s)^k * (1-p(t,s))^{n-k}$.


The code for modeling and the model estimate is below:
```{r}
challenger$prob = challenger$O.ring/challenger$Number

mod.1.full <- glm(
formula = prob ~ Temp + Pressure, 
family = binomial(link = logit),
data = challenger
)

mod.1.noPressure <- glm(
formula = prob ~ Temp, 
family = binomial(link = logit),
data = challenger 
)

mod.temp.squared <- glm(
formula = prob ~ Temp + I(Temp^2), 
family = binomial(link = logit),
data = challenger 
)

suppressWarnings(stargazer(mod.1.full, mod.1.noPressure, mod.temp.squared, type="text", keep.stat=c("n","aic"), omit.table.layout="n"))
```

The results show the estimated coefficients, standard errors, and evaluations of the goodness-of-fit, Akaike Inf.Crit. (AIC).  The model with the lowest AIC (model 2) should have the best fit vs. parsimony of explanatory variables.

Expressing the estimates in the form of models (1), (2), and (3) above yields:

$$(1): logit(\hat \pi) = 2.520 + -0.098Temp + 0.008Pressure$$
$$(2): logit(\hat \pi) = 5.085 + -0.116Temp$$
$$(3): logit(\pi) = 22.126 + -0.651Temp + 0.004Temp^2$$

Interpretting these models, for example model 1, every one unit increase in temperature will decrease the chance of failure by 0.098 units whereas every unit increase in pressure will cause a 0.008 unit increase in chance of failure. This could be understood as low temperature can make O-rings not seal properly and high pressure would be additional stress.

Beyond comparing AIC values of the models, we're also interested in the effect that each explanatory variable has on the statistical significance.  For example, is model 1 statistically equivalent to model 2.  We can do this by comparing the  $-2log(\Lambda)$, where $\Lambda$ is the likelihood ratio test (LRT), to the $\chi^2_df$ distribution, allowing us to calculate a p-value.

```{r}
cat("\nBelow results are with anova (base R package)\n")
suppressWarnings(anova(mod.1.full, mod.1.noPressure, mod.temp.squared, test = "Chisq"))
```

We see that the p-values (0.6123 and 0.7740) are not significant at $\alpha = 0.05$.  This means that all three of our models are equivalent.  Based upon this result we should proceed with the simplest model (2). [4c]

Looking at the p-value of a chi-square distribution, it seems like pressure is not as significant. This seems to coincide with conclusions reached in the paper. Using this model, we produce a confidence interval, as asked for question 4d, of the launch at 31 degrees which was the temperature the rocket was launched at.

```{r}
predicted_odds = predict(mod.1.noPressure, newdata=data.frame(Temp=31), type="link", se.fit = TRUE)
predicted_prob = exp(predicted_odds$fit)/(1+exp(predicted_odds$fit))
ci_odds = c(predicted_odds$fit - qnorm(1-.05/2)*predicted_odds$se.fit, predicted_odds$fit + qnorm(1-.05/2)*predicted_odds$se.fit)
ci = exp(ci_odds)/(1+exp(ci_odds))
"Predicted probability of at least one O-ring failure with 95% confidence interval:"
paste(round(ci[1],5), "<", round(predicted_prob,5), "<", round(ci[2],5))
```

Overall, parsimony is desirable however we wonder if there isn't some interaction effect that temperature and pressure have. One of the foundation law's of physics is the ideal gas law, PV = nRT, which relates pressure (P) and temperature (T). In addition high pressure can cause blow holes, which expose the O-ring to high temperature as stated in the paper.Therefore to remove the variable, it does open the potential for the model to not fully explain the variance and overall predictive power as well. 

With an idea of the predicted probability at 31 degrees, we plot (1) $\pi$ vs. Temp and (2) Expected number of failures vs. Temp from 31 to 81 degrees as asked in question 5b. Note that we decided to skip question 5a since that is just asking to remodel the equation. 

**CM: Can we combine the Pi vs Temp plot with the one below w/confidence intervals?  from a report perspective I think it makes more sense.  I'd also like to add a plot of the actual data on top of the predicted regression.**

**CM: I disagree with the interpretation of Pi here. As written and used below, it's exp(beta_0 + beta_1\*Temp).  Intuitively Pi should be on the scale of probablity, that is 0 to 1.  I notice that this value is used in the next couple analyses.**
```{r}

pred <- data.frame(Temp=seq(31,81))
pred.results <- predict(mod.1.noPressure, pred, type = "link", se = TRUE)

pi = exp(pred.results$fit)

plot(pred$Temp, pi, ylab = "pi", xlab = "Temp")

n = 6
pi.expected.prob = pi/(1+pi)
pi.expected.oring = n*pi.expected.prob

plot(pred$Temp, pi.expected.oring, ylab = "Expected Number of Failures", xlab = "Temp")

```

With the Wald confidence interval as asked by question 5c, the plots look like below:

```{r}
alpha = 0.05

pi.ci.lower <- exp(pred.results$fit - qnorm(p =1-alpha /2)*pred.results$se)
pi.ci.upper <- exp(pred.results$fit + qnorm(p =1-alpha /2)*pred.results$se)

pi.expected.ci.lower.prob <- (pi.ci.lower/(1+pi.ci.lower))
pi.expected.ci.upper.prob <- (pi.ci.upper/(1+pi.ci.upper))

pi.expected.ci.lower.oring <- n*pi.expected.ci.lower.prob
pi.expected.ci.upper.oring <- n*pi.expected.ci.upper.prob

results.collection <- data.frame(
Temp=pred$Temp,
pi,
pi.ci.lower,
pi.ci.upper,
pi.expected.oring,
pi.expected.ci.lower.oring, 
pi.expected.ci.upper.oring,
pi.expected.prob, 
pi.expected.ci.lower.prob,
pi.expected.ci.upper.prob
)

matplot(results.collection$Temp, results.collection[,2:4], pch=19 ,col = 1:3, ylab = "pi", xlab = "Temp")
matplot(results.collection$Temp, results.collection[,8:10], pch=19 ,col = 1:3, ylab = "prob", xlab = "Temp")

```

Looking above, the gap is wider at lower temperatures because we did not have data at those temperatures to model. This is especially evident since it can be see that around 50 degrees, the gap starts to close and it is exactly around this region where we start having data. Below is also a summary table of the calculations (Note the values at 31 degrees as asked by question 5d). 
**CM: I'd like to explain better why the confidence interval is wider when there is no data. I understand that the prediction CI's are based upon the SE and covariance matrix of the coefficients, but it's not intuitive to me why how that relates to varying Temp**
```{r}
head(results.collection,1)

```

At 31 degrees, it seems there's about 81.8% chance of failure. However, this chance should be taken cautiously. As discussed previously, there is no data below the 50 degree region therefore as validated by the large confidence interval gap, it's hard to say how accurate that zone of prediction is. We would have to assume that below 50 degrees, the behavior is linear per the model and that the effect of pressure does not change or somehow become more dominant in that zone. 

Given the described weaknesses of the Wald confidence interval, we replicate the bootstrapping method described in the paper as asked by question 5e.

```{r}
get_bootstrap_ci = function(df_number, temp){

vector <- vector("numeric")
set.seed(1)

for (i in 1:df_number) {

df.tmp <- challenger[sample(nrow(challenger), 23, replace = TRUE), ]

mod.1.tmp <- suppressWarnings(glm(
formula = prob ~ Temp, 
family = binomial(link = logit),
data = df.tmp 
))

pred.value <- data.frame(Temp=temp)
pred.result <- predict(mod.1.tmp, pred.value, type = "link", se = TRUE)
vector[i] <- exp(pred.result$fit)

}

results_sorted = sort(vector)

cat("For temp",temp,"lower ci of pi:",results_sorted[df_number*0.05], ",upper ci of pi:",results_sorted[df_number*0.95],"\n")

}

get_bootstrap_ci(100, 31)
get_bootstrap_ci(100, 72)

```

Lastly, we investigate the possibility of adding a quadratic term to the model as asked by question 5f

```{r}
mod.temp.squared <- glm(
formula = prob ~ Temp + I(Temp^2), 
family = binomial(link = logit),
data = challenger 
)

summary(mod.temp.squared)

anova(mod.1.noPressure,mod.temp.squared, test = "Chisq")

```

Given the high p-value of the squared term in both the model summary and anova test, it doesn't seem like the squared term is necessary. The residual deviance decreased slightly from 3.01 to 2.93 (~3%) and the AIC increased from 7.2 to 9.2. To summarize our final model in terms of both odds and probability of failure.

The final model is $logit(\pi) = \beta_0 + \beta_1Temp$. In terms of odds, we can see that the odds ratio can be calculated simply as $\frac{exp(\beta_0 + \beta_1(Temp+c))}{exp(\beta_0 + \beta_1(Temp))}$ which simplifies to $exp(c\beta_1)$. Thusly, because the coefficient of temp is -0.1156, the estimated odds of an O-ring failing decreases by 0.890 times for every c-unit increases in temp. In terms of the probability of failure as seen below, it is very clear that the probability of there being a failure is high when the temperature is low (81.2% at 31 degrees) and this changes as the temperature increases (1.36% at 81 degrees).

In the above analysis, we used a combination of logistic regression and binomial theory to calculate a probability and expected number of failures. How does this compare to a traditional linear model? We also perform a classical linear regression to compare.

```{r}
mod.lin <- lm(

formula = prob ~ Temp, 
data = challenger 

)

summary(mod.lin)
par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))
plot(mod.lin, las = 1)
```

**Hmm, maybe having quadratic is a good idea??**

Looking at the above diagnostic plots of the linear model $prob = \beta_0 + \beta_1Temp$, we can see that it is not ideal. The residual vs fitted and scale-location plot indicate some sort of non-linear relationship in the data and that the variance is not constant across samples (heteroscadastic). Furthermore, there appears to be outliers. Data points, 14 and 21 are marked above as having considerable leverage. In the data, these were cases where 2 O-rings failed instead of either 1 or 0. Because the vast majority of data points are those where O-rings only failed once or not at all, these two data points are skewing the model. In addition like logistic regression, this model would need independence from all discriptive variables and that is not the case as seen with pressure having some kind of affect. 

Overall, I would prefer to use the binary logistic model since it is a more conservative model in its approach. A logistic model is advantageous since it does not require a linear relationship between the dependent and independent variables, the residuals do not need to be normally distributed and lastly, homoscedasticity is not required. Also, a logistic model outputs probabilities as its main result. This is much more useful given the circumstance since one O-ring failure is all that's needed for catastrophic disaster. In other words, its easier to say "what is the probability of failure with these given conditions" via the logistic model versus "What conditions will lead to a prediction of 1 or more".

**Conclusion**

We explored three logistic regression models and one linear regression model in this analysis.  Based upon statistical examination of these models, we have concluded that the model $logit(\pi) = \beta_0 + \beta_1 * Temp$ is most suitable.  Our analysis and results are consistent with the finding of Dalal et al (1989).

The other logistic regression models tested did not describe a greater amount of the variance in data and were more complicated.  This is demonstrated by the AIC value for the chosen model (7.2026) versus the +Pressure and Temp^2 models (9.2286 and 9.2373).

The linear regression model was deemed unsuitable since the underlying Classical Linear Model assumptions were not met.  This especially reduces our confidence that model would be able to predict a failure probability in a region of the regression for which there was no data. 


**References**

[1] Dalal, Siddhartha R., Edward B. Fowlkes, and Bruce Hoadley. "Risk analysis of the space shuttle: Pre-Challenger prediction of failure." Journal of the American Statistical Association 84.408 (1989): 945-957.

[2] Bilder, Christopher R., Loughin, Thomas M.. Analysis of Categorical Data with R (Chapman & Hall/CRC Texts in Statistical Science). CRC Press (2015). 

[3] Kelly, Dana L., and Curtis L. Smith. "Risk analysis of the space shuttle: pre-challenger bayesian prediction of failure." NASA Space Systems Engineering and Risk Management (2008).

[4] Simonoff, J. "The Flight of the Space Shuttle Challenger." (2017) http://people.stern.nyu.edu/jsimonof/classes/2301/pdf/challlog.pdf

**Appendix**

(4a) The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

(4b) Estimate the logistic regression model using the explanatory variables in a linear form.

(4c) Perform LRTs to judge the importance of the explanatory variables in the model.

(4d) The temperature was $31\textdegree$ at launch for the Challenger in 1986.  Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval.  Discuss what assumptions need to be made in order to apply the inference procedures.

5. Continuing Exercise 4, consider the simplified model $logit(\pi) = \beta_0 + \beta_1Temp$ where $\pi$ is the probability of an O-ring failure. Complete the following:

(a) Estimate the model.

(b) Construct two plots: (1) $\pi$ vs. Temp and (2) Expected number of failures vs. Temp. Use a temperature range of 31 to 81 degrees on the x-axis even though the minimum temperature in the data set was 53 degrees.

(c) Include the 95% Wald confidence interval bands for on the plot. Why are the bands much wider for lower temperatures than for higher temperatures?

(d) The temperature was 31 degrees at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in
order to apply the inference procedures.

(e) Rather than using Wald or profile LR intervals for the probability of failure, Dalal et al. (1989) use a parametric bootstrap to compute intervals. Their process was to (1) simulate a large number of data sets (n = 23 for each) from the estimated model of $logit(\hat{\pi}) = \hat{\beta_0} + \hat{\beta_1}Temp$; (2) estimate new models for each data set,
say $logit(\hat{\pi^{*}}) = \hat{\beta_0^{*}} + \hat{\beta_1^{*}}Temp$; and (3) compute $\hat{\pi^{*}}$ at a specific temperature of interest. The authors used the 0.05 and 0.95 observed quantiles from the $\hat{\pi^{*}}$ simulated distribution as their 90% confidence interval limits. Using the parametric bootstrap, compute 90% confidence intervals separately at temperatures of 31 and 72 degrees.

(f) Determine if a quadratic term is needed in the model for the temperature.

3a. Interpret the main result of your final model in terms of both odds and probability of failure.

3b. With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions.  Would you use the linear regression model or binary logistic regression in this case.  Please explain.